# Infrared images generatio and image fusion

## Introduction


## Demo
### Object detection
### Object recognition



## Algorithm Explanation
### Object detection
![Process]()
In order to reduce the *loss* function from falling into the local optimum during the training process. We first gradient processed the *loss* function, as follows:
### Object recognition

## Instruction
### Object detection
Open random_make_patch.py, set the parameters you need in the parameter list, and start running.

* **Model loading**: First, the required model will be loaded from the pretrained_models_pytorch/pretrainedmodels folder. If it is target recognition, the model parameters of the corresponding network will be downloaded through the Internet. If it is target detection, the model will be loaded in yolo.py in the folder. and return.

* **Sample loading**: After the model is loaded, the Dataloader will load all images and labels from the corresponding folder where the training data is stored.

* **Training process**: Use the loaded images and models in random_make_patch.py to train adversarial samples. The finally generated adversarial samples, original images, original prediction images, and post-attack prediction images are stored in the advspec folder at the same level. The results generated by the attack will be saved to predict_results_without_attack.json.

* **Evaluate**: Use the coco toolbox to compare the saved json and the original new.json and generate the pr curve and store it in prcurve at the same level.
### Object recognition

* **Model loading**: Open the test_deepfool.py or test_CWattack file, read the original sample and target sample in the images, and input them into the network to obtain the category of the original sample and the category of the target sample. Use the category of the target sample as the target of targeted confrontation.
  
* **Training process**: Use deepfool and CWattack perturb the sample, and the output result includes a picture composed of the perturbation.

* **Evaluate**: After perturbation, the picture, the number of iterations, the original category, the target category, the category of the interfered image, and put the interfered image into the corresponding out file.
